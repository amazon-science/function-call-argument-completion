{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "from generate.constant import ignore_functions\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def filter_function(item):\n",
    "    if item[\"name\"] in ignore_functions:\n",
    "        return True\n",
    "    if item[\"name\"].endswith(\"Error\"):\n",
    "        return True\n",
    "    if item[\"name\"].startswith(\"write\"):\n",
    "        return True\n",
    "    if item[\"name\"].startswith(\"assert\"):\n",
    "        return True\n",
    "    if item[\"name\"] in [\"isinstance\", \"repr\", \"str\", \"int\", \"bool\", \"float\", \"list\", \"tuple\", \"type\", \"set\", \"dict\"]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def package_name(x):\n",
    "    j = -1\n",
    "    lis = x.split(\"/\")\n",
    "    for i, y in enumerate(lis):\n",
    "        if y==\"site-packages\":\n",
    "            j = i\n",
    "            break\n",
    "    assert j>-1\n",
    "    x = lis[j+1]\n",
    "    return x\n",
    "\n",
    "def rectify(x):\n",
    "    return \", \".join([y.strip() for y in x.split(\",\")])\n",
    "\n",
    "def indent(text, ind):\n",
    "    cur = \"\\n\".join([x[ind:] if len(x[:ind].strip())==0 else x for x in text.split(\"\\n\") if len(x.strip())>0])\n",
    "    return cur\n",
    "\n",
    "def mask_single_function(folder, path, calls, edges, max_line=30):\n",
    "    with open(path) as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    lines = text.split(\"\\n\")\n",
    "    lengths = [0]\n",
    "    for x in lines:\n",
    "        y = len(x)+1 + lengths[-1]\n",
    "        lengths.append(y)\n",
    "    lengths[-1] -= 1\n",
    "    assert lengths[-1] == len(text)\n",
    "    def loc(lineno, offset):\n",
    "        return lengths[lineno] + offset\n",
    "    \n",
    "    res_lis = []\n",
    "    for item in calls:\n",
    "        if filter_function(item):\n",
    "            continue\n",
    "            \n",
    "        arg_x = loc(item[\"args_position\"][\"line\"], item[\"args_position\"][\"character\"])\n",
    "        arg_y = loc(item[\"args_position\"][\"end_line\"], item[\"args_position\"][\"end_character\"])\n",
    "        target = rectify(text[arg_x:arg_y])\n",
    "        if not target.startswith(\"(\"):\n",
    "            continue\n",
    "            \n",
    "        if target == \"()\": continue\n",
    "        if target.find(\"'\")!=-1 or target.find('\"')!=-1:\n",
    "            continue\n",
    "        if not target.endswith(\")\"):\n",
    "            continue\n",
    "            \n",
    "        target = target[1:]\n",
    "        if item[\"context\"] is None:\n",
    "            continue\n",
    "\n",
    "        arg_x = loc(item[\"args_position\"][\"line\"], item[\"args_position\"][\"character\"])\n",
    "        arg_y = loc(item[\"args_position\"][\"end_line\"], item[\"args_position\"][\"end_character\"])\n",
    "        ind = item[\"context\"][\"character\"]\n",
    "        cx = loc(item[\"context\"][\"line\"], 0)\n",
    "        cy = loc(item[\"context\"][\"end_line\"], item[\"context\"][\"end_character\"])\n",
    "        if cx>=arg_x:\n",
    "            continue\n",
    "\n",
    "        ty = 0\n",
    "        if item[\"definition\"] is None:\n",
    "            continue\n",
    "        elif item[\"definition\"][0][\"uri\"].find(folder)!=-1:\n",
    "            ty = 0 # in this project\n",
    "        elif item[\"definition\"][0][\"uri\"].find(\"/home/ubuntu/mydata/jedi/\")!=-1 or item[\"definition\"][0][\"uri\"].find(\"/home/ubuntu/anaconda3/lib/\")!=-1:\n",
    "            ty = 2 # stdlib of python\n",
    "        else:\n",
    "            ty = 1 # from other dependencies\n",
    "            x = item[\"definition\"][0][\"uri\"]\n",
    "            if x.startswith(\"file://\"):\n",
    "                x = x[7:]\n",
    "            x = package_name(x)\n",
    "            edges.add(x)\n",
    "\n",
    "        cur = item.copy()\n",
    "        cur[\"context_position\"] = cur[\"context\"].copy()\n",
    "        cur[\"context\"] = (indent(text[cx:arg_x], ind), indent(text[arg_y:cy], ind))\n",
    "        cur[\"target\"] = target\n",
    "        cur[\"type\"] = ty\n",
    "        cur[\"folder\"] = folder \n",
    "        cur[\"path\"] = path\n",
    "        res_lis.append(cur)\n",
    "            \n",
    "    return res_lis, edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = pickle.load(open(\"/home/ubuntu/mydata/src_env.pkl\", \"rb\"))\n",
    "src = {x:y for x,y in src}\n",
    "pj2name = {}\n",
    "name2pj = {}\n",
    "dir_lis = [\"/home/ubuntu/mydata/extract/\"]\n",
    "for direc in dir_lis:\n",
    "    for file in tqdm(os.listdir(direc)):\n",
    "        if not file.endswith(\".json\"): continue\n",
    "        with open(os.path.join(direc, file)) as f:\n",
    "            dic = json.load(f)\n",
    "        folder = src[file[:-5]]\n",
    "        name = package_name(folder) \n",
    "        if name2pj.get(name) is None:\n",
    "            name2pj[name] = (file[:-5], len(dic))\n",
    "        elif name2pj[name][1]<len(dic):\n",
    "            name2pj[name] = (file[:-5], len(dic))\n",
    "            \n",
    "for name, (pj, _) in name2pj.items():\n",
    "    pj2name[pj] = name\n",
    "print(len(pj2name))\n",
    "print(len(name2pj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = {}\n",
    "all_edges = {}\n",
    "for direc in dir_lis:\n",
    "    for file in tqdm(os.listdir(direc)):\n",
    "        if not file.endswith(\".json\"): continue\n",
    "        with open(os.path.join(direc, file)) as f:\n",
    "            dic = json.load(f)\n",
    "        pj = file[:-5]\n",
    "        if pj2name.get(pj) is None: continue\n",
    "        folder = src[pj]\n",
    "        res_lis = []\n",
    "        edges = set()\n",
    "        tot[pj] = {}\n",
    "        for k in dic:\n",
    "            if len(dic[k])==0: continue\n",
    "            res, edges = mask_single_function(folder, k, dic[k], edges)\n",
    "            res_lis.extend(res)\n",
    "        tot[pj] = res_lis\n",
    "        all_edges[pj2name[pj]] = edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "du = {}\n",
    "for x,y in pj2name.items():\n",
    "    du[y] = 0 \n",
    "for x in all_edges:\n",
    "    edges = all_edges[x]\n",
    "    for y in edges:\n",
    "        if du.get(y) is None:\n",
    "            continue\n",
    "        du[y]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5fe2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "license = pickle.load(open(\"/home/ubuntu/mydata/license.pkl\", \"rb\"))\n",
    "allow = [\"MIT\", \"Apache\", \"BSD\", \"CC0\", \"ZPL 2.1\", \"ISCL\", \"PSF\", \"Python Software Foundation License\", \"HPND\"]\n",
    "\n",
    "def rough(x):\n",
    "    lis = [\"BSD\",\"MIT\",\"Apache\", \"MPL\", \"LGPL\",\"GPL\",\"AFL\",\"ISCL\",\"PSF\",\"ZPL 2.1\",\"CC0\", \"HPND\",\"EPL\",\n",
    "           \"Python Software Foundation License\", \"Other/Proprietary License\", \"Public Domain\"]\n",
    "    for i in lis:\n",
    "        if x.find(i)!=-1:\n",
    "            return i\n",
    "    if len(x)==0: return \"\"\n",
    "    return None\n",
    "\n",
    "def check_license(name):\n",
    "    pj = name2pj[name][0]\n",
    "    if rough(license.get(pj, \"\")) not in allow:\n",
    "        return False\n",
    "    for x in all_edges[name]:\n",
    "        if x not in name2pj:\n",
    "            return False\n",
    "        nw = name2pj[x][0]\n",
    "        assert nw in pj2name\n",
    "        if rough(license.get(nw, \"\")) not in allow:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "lis = sorted(list(name2pj.keys()))\n",
    "pub_lis = [x for x in lis if check_license(x)]\n",
    "print(len(pub_lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e524211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_t1(t):\n",
    "    t1 = set(t)\n",
    "    for x in t:\n",
    "        for y in all_edges[x]:\n",
    "            t1.add(y)\n",
    "    return t1\n",
    "\n",
    "def potential_training_set(t):\n",
    "    t1 = find_t1(t)    \n",
    "    potentials = {1:[], 2:[], 3:[], 4:[]}\n",
    "    for x in pub_lis:\n",
    "        if x in t: continue\n",
    "        potentials[1].append(x)\n",
    "        if len(all_edges[x]&set(t))>0: continue\n",
    "        potentials[2].append(x)    \n",
    "        if x in t1: continue\n",
    "        potentials[3].append(x)\n",
    "        if len(all_edges[x]&t1)>0: continue\n",
    "        potentials[4].append(x)\n",
    "        \n",
    "    return potentials\n",
    "\n",
    "def calls(lis):\n",
    "    nw = [name2pj[x][0] for x in lis]\n",
    "    return sum([len(tot[x]) for x in nw])\n",
    "\n",
    "def types(lis):\n",
    "    nw = [name2pj[x][0] for x in lis]\n",
    "    cnt = Counter()\n",
    "    for x in nw:\n",
    "        sub = [y[\"type\"] for y in tot[x]]\n",
    "        cnt.update(sub)\n",
    "    print(cnt)\n",
    "    \n",
    "for f in [0.01, 0.033, 0.05, 0.1, 0.11]:\n",
    "    #lis = [x for x in du if du[x]==0]\n",
    "    _, test = train_test_split(pub_lis, test_size=f, random_state=42)\n",
    "    p = potential_training_set(test)\n",
    "    t1 = find_t1(test)\n",
    "    \n",
    "    print(\"test set, projects:\", len(test), \", t1 projects\", len(t1), \", function calls:\", calls(test))\n",
    "    #types(test)\n",
    "    for k in p:\n",
    "        num = calls(p[k])\n",
    "        print(f\"level {k}, training projects:\", len(p[k]), \", function calls: \", num)\n",
    "        types(p[k])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc5a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.utils import make_sure_path_exists\n",
    "def flatten(lis):\n",
    "    al = []\n",
    "    for x in lis:\n",
    "        al.extend(tot[name2pj[x][0]])\n",
    "    return al\n",
    "\n",
    "def level4check(s0, t0):\n",
    "    s1 = set(s0)\n",
    "    t1 = set(t0)\n",
    "    for x in s0:\n",
    "        s1.update(all_edges[x])\n",
    "    for x in t0:\n",
    "        t1.update(all_edges[x])\n",
    "    assert len(set(s1)&set(t1))==0\n",
    "    \n",
    "path = \"/home/ubuntu/mydata/pkl_data/distributable/\"\n",
    "make_sure_path_exists(path)\n",
    "for f in [0.1]:\n",
    "    _, test = train_test_split(pub_lis, test_size=f, random_state=42)\n",
    "    p = potential_training_set(test)\n",
    "    t1 = find_t1(test)\n",
    "    n0 = calls(test)\n",
    "    print(\"valid + test set, projects:\", len(test), \", t1 projects\", len(t1), \", function calls:\", n0)\n",
    "    #types(test)\n",
    "    valid, test = train_test_split(test, test_size=0.5, random_state=2333)\n",
    "    test_data = flatten(test)\n",
    "    valid_data = flatten(valid)\n",
    "    assert len(test_data) + len(valid_data) == n0\n",
    "    print(len(valid), len(valid_data), len(test), len(test_data))\n",
    "    for k in p:\n",
    "        if k!=4: \n",
    "            continue\n",
    "        else:\n",
    "            level4check(p[k], valid+test)\n",
    "        make_sure_path_exists(f\"{path}/level{k}\")\n",
    "        num = calls(p[k])\n",
    "        print(f\"level {k}, training projects:\", len(p[k]), \", function calls: \", num)\n",
    "        train_data = flatten(p[k])\n",
    "        cur_path = f\"/home/ubuntu/mydata/pkl_data/distributable/level{k}\"\n",
    "        \"\"\"\n",
    "        if len(train_data) > len(test_data) * 8:\n",
    "            cur_path += \"/sampled/\"\n",
    "            _, train_data = train_test_split(train_data, test_size=len(test_data) * 8, random_state=42)\n",
    "            print(\"sample\", len(train_data))\n",
    "        else:\n",
    "            print(len(train_data))\n",
    "        \"\"\"\n",
    "        \n",
    "        with open(f\"{cur_path}/train.pkl\", \"wb\") as f:\n",
    "            pickle.dump(train_data, f)\n",
    "        with open(f\"{cur_path}/dev.pkl\", \"wb\") as f:\n",
    "            pickle.dump(valid_data, f)\n",
    "        with open(f\"{cur_path}/test.pkl\", \"wb\") as f:\n",
    "            pickle.dump(test_data, f)\n",
    "            \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddb69a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
