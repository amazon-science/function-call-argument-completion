{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda94ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "import pickle\n",
    "import json\n",
    "import ast\n",
    "import astor\n",
    "path = \"/home/ubuntu/mydata/pkl_data/distributable/level4_inter\"\n",
    "dic = {}\n",
    "with open(f\"{path}/train.pkl\", \"rb\") as f:\n",
    "    dic[\"train\"] = pickle.load(f)\n",
    "with open(f\"{path}/dev.pkl\", \"rb\") as f:\n",
    "    dic[\"dev\"] = pickle.load(f)\n",
    "with open(f\"{path}/test.pkl\", \"rb\") as f:\n",
    "    dic[\"test\"] = pickle.load(f)\n",
    "src = pickle.load(open(\"/home/ubuntu/mydata/src_env.pkl\", \"rb\"))\n",
    "src = {x:y for x,y in src}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = 0\n",
    "def get_implementation(item, loc, no_comment=False, only_init=False):\n",
    "    def check_ind(string):\n",
    "        return len(string) - len(string.lstrip())\n",
    "    file = loc[\"uri\"][7:]\n",
    "    try:\n",
    "        with open(file, errors='ignore') as f:\n",
    "            text = f.read()\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    lines = text.split(\"\\n\")\n",
    "    be = loc[\"range\"][\"start\"]['line']\n",
    "    en = loc[\"range\"][\"end\"]['line']\n",
    "    if len(lines)<=be:\n",
    "        print(loc[\"range\"])\n",
    "        print(file)\n",
    "        print(item[\"name\"])\n",
    "        return \"\"\n",
    "    \n",
    "    ind = check_ind(lines[be])\n",
    "    if not lines[be].strip().startswith(\"def \") and not lines[be].strip().startswith(\"class \"):\n",
    "        return \"\"\n",
    "        \n",
    "    lis = []\n",
    "    for j in range(be, len(lines)):\n",
    "        if len(lines[j].strip())==0: continue\n",
    "        if check_ind(lines[j]) <= ind and j>be and not lines[j].strip().startswith(\")\"):\n",
    "            break\n",
    "        if only_init:\n",
    "            if lines[be].strip().startswith(\"class \"):\n",
    "                if lines[j].strip().startswith(\"def \") and \\\n",
    "                    not lines[j].strip().startswith(\"def __init__\") and check_ind(lines[j])==ind+4:\n",
    "                    break\n",
    "        if file == item[\"path\"] and lines[be].find(\"def \"+item[\"name\"]+\"(\")!=-1 and j==item[\"position\"][\"line\"]:\n",
    "            global cases\n",
    "            cases +=1 \n",
    "            break\n",
    "        lis.append(lines[j][ind:])\n",
    "\n",
    "    if no_comment:\n",
    "        for i in range(len(lis)):\n",
    "            if i==0:\n",
    "                body = \"\\n\".join(lis)\n",
    "            else:\n",
    "                body = \"\\n\".join(lis[:-i])\n",
    "            try:\n",
    "                node = ast.parse(body)\n",
    "            except Exception as e:\n",
    "                continue \n",
    "            node = node.body[0]\n",
    "            if isinstance(node.body[0], ast.Expr):\n",
    "                if hasattr(node.body[0], 'value') and isinstance(node.body[0].value, ast.Str):\n",
    "                    node.body = node.body[1:]\n",
    "            body = astor.to_source(node)\n",
    "            return body\n",
    "        \n",
    "    return \"\\n\".join(lis)\n",
    "    \n",
    "print(get_implementation(dic[\"train\"][1863], dic[\"train\"][1863][\"definition\"][0]))\n",
    "print(get_implementation(dic[\"test\"][0], dic[\"test\"][0][\"definition\"][0]))\n",
    "print(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a668c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for k in dic:\n",
    "    for x in tqdm(dic[k]):\n",
    "        for loc in x[\"definition\"]:\n",
    "            new_body = get_implementation(x, loc)\n",
    "            loc[\"body\"] = new_body\n",
    "print(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c794dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(x):\n",
    "    flag = 0\n",
    "    for loc in x[\"definition\"]:\n",
    "        if len(loc[\"body\"].strip())==0: \n",
    "            continue\n",
    "        #if loc[\"uri\"].endswith(\"pyi\"):\n",
    "        #    continue\n",
    "        flag +=1\n",
    "    return flag\n",
    "\n",
    "for k in dic:\n",
    "    s = 0\n",
    "    for i, x in enumerate(dic[k]):\n",
    "        if check(x)==1:\n",
    "            s+=1\n",
    "\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, lis in dic.items():\n",
    "    new_lis = [x for x in lis if len(x[\"context\"][0].strip())>0 and check(x)>0]\n",
    "    print(len(new_lis), len(lis))\n",
    "    with open(f\"/home/ubuntu/mydata/pkl_data/distributable/level4_inter/{k}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(new_lis, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907edc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
